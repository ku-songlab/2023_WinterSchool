{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- ---\n",
        "- Project: 2023 Winter School\n",
        "- Author: Gyu-min Lee\n",
        "- Version: 0.5\n",
        "- Changelog\n",
        "    - 0.1 -- Initiated the file\n",
        "    - 0.5 -- First Draft\n",
        "--- -->"
      ],
      "metadata": {
        "id": "Q9gzdxqAsnsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2023 전산언어학 겨울학교 5일차 1교시\n",
        "\n",
        "# Syntax "
      ],
      "metadata": {
        "id": "sKVGZDums7tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project: SNLI with ALBERT \n",
        "\n",
        "- 🤗 Hub의 모델과 데이터셋을 불러와 파인튜닝 및 성능 평가를 진행합니다\n",
        "- 📔NOTE: 빠른 실행을 위해 Runtime 유형을 'GPU'로 해 주세요"
      ],
      "metadata": {
        "id": "tBXi4nFXH3se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.26.0 datasets==2.9.0"
      ],
      "metadata": {
        "id": "kp5yCyN_H3c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP0: Load libraries\n",
        "import random\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "import datasets\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "PAqjQ3okIipN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP1: Prepare models\n",
        "MODEL_NAME = \"albert-base-v2\"\n",
        "# https://huggingface.co/albert-base-v2\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
        "                                           num_labels = 3)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "hZZFdn97KF_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP2: Prepare data\n",
        "DATASET_NAME = \"snli\"\n",
        "# https://huggingface.co/datasets/snli\n",
        "\n",
        "dataset = datasets.load_dataset(DATASET_NAME)\n",
        "dataset"
      ],
      "metadata": {
        "id": "GALIQE2T8Jnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(dataset):\n",
        "    text = dataset['premise'] + ' ' + dataset['hypothesis']\n",
        "    result = text.lower()\n",
        "    result = tokenizer(result, truncation=True)\n",
        "\n",
        "    return result "
      ],
      "metadata": {
        "id": "Q_YWWgBeVAwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].select(random.sample(range(len(dataset['train'])), 7000))\n",
        "dataset['test'] = dataset['test'].select(random.sample(range(len(dataset['test'])), 2000))\n",
        "dataset['validation'] = dataset['validation'].select(random.sample(range(len(dataset['validation'])), 1000))\n",
        "# sampling the data for demonstration purpose only"
      ],
      "metadata": {
        "id": "ucFCcJV6adNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].map(preprocess)\n",
        "dataset['test'] = dataset['test'].map(preprocess)\n",
        "dataset['validation'] = dataset['validation'].map(preprocess)"
      ],
      "metadata": {
        "id": "mAVhWSLtWBQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'] = dataset['train'].rename_column(\"label\", \"labels\")\n",
        "dataset['test'] = dataset['test'].rename_column(\"label\", \"labels\")\n",
        "dataset['validation'] = dataset['validation'].rename_column(\"label\", \"labels\")\n",
        "\n",
        "\n",
        "dataset['train'] = dataset['train'].filter(lambda x: x['labels'] != -1) \n",
        "dataset['test'] = dataset['test'].filter(lambda x: x['labels'] != -1)\n",
        "dataset['validation'] = dataset['validation'].filter(lambda x: x['labels'] != -1)"
      ],
      "metadata": {
        "id": "2HOYZBjzb9jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP3: Set up a trainer\n",
        "\n",
        "def metrics(model_output) -> dict:\n",
        "    labels = model_output.label_ids\n",
        "    predictions = model_output.predictions.argmax(-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy,\n",
        "            \"f1\": f1}\n",
        "            \n",
        "training_args = TrainingArguments(num_train_epochs=1,\n",
        "                                    # probably increase epochs for better result\n",
        "                                    output_dir='./checkpoints',\n",
        "                                    per_device_train_batch_size=64,\n",
        "                                    per_device_eval_batch_size=128,\n",
        "                                    evaluation_strategy='steps', # or, 'epoch'\n",
        "                                    logging_dir='./checkpoints/logs',\n",
        "                                    logging_steps=50,\n",
        "                                    save_steps=100,\n",
        "                                    load_best_model_at_end=True,\n",
        "                                    )\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                    args=training_args,\n",
        "                    train_dataset=dataset[\"train\"], \n",
        "                    eval_dataset=dataset[\"validation\"],\n",
        "                    tokenizer=tokenizer,\n",
        "                    compute_metrics=metrics,\n",
        "                )\n",
        "                          "
      ],
      "metadata": {
        "id": "6yg3b4HwbKzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "RNQoBM1kU_DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP4: train\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "_RxpzkImcRda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP5: predict\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
        "\n",
        "pipe = pipeline(task='text-classification',\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                device=DEVICE,\n",
        "                )\n",
        "\n",
        "test_inputs =  [data['premise'] + ' ' + data['hypothesis'] for data in dataset['test']]\n",
        "test_labels = [data['labels'] for data in dataset['test']]\n",
        "\n",
        "preds = pipe(test_inputs)\n"
      ],
      "metadata": {
        "id": "BkimZhN-cSst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds[:10]"
      ],
      "metadata": {
        "id": "TrWpumeUfIkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [0 if pred['label'] == \"LABEL_0\" \n",
        "         else 1 if pred['label'] == \"LABEL_1\" else 2\n",
        "         for pred in preds]\n"
      ],
      "metadata": {
        "id": "jCmOJdMsfKI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accruacy = accuracy_score(test_labels, preds)\n",
        "f1 = f1_score(test_labels, preds, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: \\t{accruacy:04.2f}\")\n",
        "print(f\"F1: \\t{f1:04.2f}\")"
      ],
      "metadata": {
        "id": "g-l85mW8fx6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRA: saving the dataset\n",
        "import json\n",
        "\n",
        "test_dict = dataset['test'].to_dict()\n",
        "# to_dict, to_csv, to_pandas\n",
        "\n",
        "with open('out.json', 'w') as f:\n",
        "    json.dump(test_dict, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "QW0Dw52Ygo62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict.keys()"
      ],
      "metadata": {
        "id": "ewTfr5kihUCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 30 out.json"
      ],
      "metadata": {
        "id": "xd4Hl_iZiT6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCNMkjj4ix_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}